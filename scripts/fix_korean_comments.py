#!/usr/bin/env python3
"""
Script to convert Korean comments and docstrings to English
in the ranx-k codebase following CLAUDE.md guidelines.
"""

import os
import re
from pathlib import Path

# Translation mappings
TRANSLATIONS = {
    # OpenAI specific terms
    "OpenAI Embeddings APIë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚°ê¸°": "Similarity calculator using OpenAI Embeddings API",
    "OpenAI ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°ê¸° ì´ˆê¸°í™”": "Initialize OpenAI embedding similarity calculator",
    "ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ ê°œìˆ˜": "Number of texts to process",
    "í…ìŠ¤íŠ¸ë‹¹ í‰ê·  í† í° ìˆ˜": "Average tokens per text",
    "OpenAI ëª¨ë¸ëª…": "OpenAI model name",
    "ë¹„ìš© ì •ë³´ ë”•ì…”ë„ˆë¦¬": "Cost information dictionary",
    # Module/file descriptions
    "ê¸°ë³¸ í† í¬ë‚˜ì´ì € ì‚¬ìš© ì˜ˆì œ": "Basic Tokenizer Usage Example",
    "ì´ ì˜ˆì œëŠ” KiwiTokenizerì˜ ê¸°ë³¸ ì‚¬ìš©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤": "This example demonstrates the basic usage of KiwiTokenizer",
    "ì¢…í•© í‰ê°€ ë¹„êµ ì˜ˆì œ": "Comprehensive Evaluation Comparison Example", 
    "ëª¨ë“  í‰ê°€ ë°©ë²•ì„ ì¢…í•©ì ìœ¼ë¡œ ë¹„êµí•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤": "Comprehensively compares and analyzes all evaluation methods",
    "ROUGE í‰ê°€ ì˜ˆì œ": "ROUGE Evaluation Example",
    "ì»¤ìŠ¤í…€ ê²€ìƒ‰ê¸° êµ¬í˜„ ì˜ˆì œ": "Custom Retriever Implementation Example",
    "BGE-M3 ëª¨ë¸ì„ ì‚¬ìš©í•œ í•œêµ­ì–´ RAG í‰ê°€ ì˜ˆì œ": "Korean RAG Evaluation Example Using BGE-M3 Model",
    "OpenAI Embeddingsë¥¼ ì‚¬ìš©í•œ í•œêµ­ì–´ RAG í‰ê°€ ì˜ˆì œ": "Korean RAG Evaluation Example Using OpenAI Embeddings",
    
    # Common function/class descriptions
    "ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜": "Main execution function",
    "ì¢…í•© í‰ê°€ë¥¼ ìœ„í•œ ê³ ë„í™”ëœ ê²€ìƒ‰ê¸°": "Advanced retriever for comprehensive evaluation",
    "ì˜ˆì œìš© ê°€ìƒ ê²€ìƒ‰ê¸°": "Example virtual retriever",
    "í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ê²€ìƒ‰ê¸°": "Simple test retriever",
    "ê°„ë‹¨í•œ ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ê¸°": "Simple vector-based retriever",
    "í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ê¸°": "Keyword-based retriever",
    "í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°": "Hybrid retriever",
    
    # Technical terms
    "ê¸°ë³¸ í˜•íƒœì†Œ ë¶„ì„ í† í¬ë‚˜ì´ì €": "Basic morphological analysis tokenizer",
    "ëª…ì‚¬ ì¶”ì¶œ í† í¬ë‚˜ì´ì €": "Noun extraction tokenizer",
    "ë¶ˆìš©ì–´ ì»¤ìŠ¤í„°ë§ˆì´ì§•": "Stopword customization",
    "í† í¬ë‚˜ì´ì € ë¹„êµ": "Tokenizer comparison",
    "í† í¬ë‚˜ì´ì € ì„±ëŠ¥ í…ŒìŠ¤íŠ¸": "Tokenizer performance test",
    "ì„±ëŠ¥ íŠ¹ì„± ë¶„ì„": "Performance characteristics analysis",
    
    # Evaluation terms
    "ê°„ë‹¨í•œ Kiwi ROUGE í‰ê°€": "Simple Kiwi ROUGE evaluation",
    "í–¥ìƒëœ ROUGE í‰ê°€": "Enhanced ROUGE evaluation",
    "ìœ ì‚¬ë„ ê¸°ë°˜ ranx í‰ê°€": "Similarity-based ranx evaluation",
    "ì¢…í•© í‰ê°€": "Comprehensive evaluation",
    "ìƒì„¸ ì„±ëŠ¥ ë¶„ì„": "Detailed performance analysis",
    "ê²°ê³¼ ë¶„ì„": "Result analysis",
    "ì„±ëŠ¥ ë¹„êµ": "Performance comparison",
    
    # Data and processing
    "í‰ê°€ìš© ë°ì´í„°ì…‹ ìƒì„±": "Create evaluation dataset",
    "TF-IDF ê¸°ë°˜ ê²€ìƒ‰": "TF-IDF based search",
    "ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°": "Relevance score calculation",
    "ì§ˆë¬¸ë³„ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„": "Question-wise search result analysis",
    
    # System components
    "RAG í‰ê°€ ë°©ë²• ì¢…í•© ë¹„êµ": "Comprehensive Comparison of RAG Evaluation Methods",
    "ë¹„ìš© ì¶”ì •": "Cost estimation",
    "ì‚¬ìš©ëŸ‰ì— ë”°ë¼ ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤": "Costs are incurred based on usage",
    
    # Status and messages
    "ë§¤ìš° ì¢‹ìŒ": "Very Good",
    "ì–‘í˜¸": "Good", 
    "ë³´í†µ": "Average",
    "ë‚®ìŒ": "Low",
    "ì¶”ì²œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤": "Recommended Usage Scenarios",
    
    # Common comments
    "ê¸°ë³¸ ë¶ˆìš©ì–´ë¡œ í† í°í™”": "Tokenization with default stopwords",
    "ì»¤ìŠ¤í…€ ë¶ˆìš©ì–´ ì¶”ê°€": "Add custom stopwords", 
    "í˜„ì¬ ë¶ˆìš©ì–´ í™•ì¸": "Check current stopwords",
    "ë¶ˆìš©ì–´ ì‚¬ìš© vs ë¯¸ì‚¬ìš©": "Stopwords usage vs non-usage comparison",
    "ê° ë¬¸ì„œì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°": "Calculate relevance score for each document",
    "ê°„ë‹¨í•œ TF-IDF ì ìˆ˜ ê³„ì‚°": "Simple TF-IDF score calculation",
    "ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬": "Sort by score",
    "ë„ë©”ì¸ë³„ ë¬¸ì„œ ì»¬ë ‰ì…˜": "Domain-specific document collection",
    "ìì—°ì–´ì²˜ë¦¬ ê´€ë ¨": "Natural language processing related",
    "ì •ë³´ ê²€ìƒ‰ ê´€ë ¨": "Information retrieval related", 
    "í‰ê°€ ë©”íŠ¸ë¦­ ê´€ë ¨": "Evaluation metrics related",
    "ë¨¸ì‹ ëŸ¬ë‹ ê´€ë ¨": "Machine learning related",
    "ë”¥ëŸ¬ë‹ ê´€ë ¨": "Deep learning related",
    "í‰ê°€ìš© ì§ˆë¬¸-ë‹µë³€ ìŒ": "Question-answer pairs for evaluation",
    "ê° ì§ˆë¬¸ì— ëŒ€í•œ ì •ë‹µ ë¬¸ì„œë“¤": "Correct documents for each question",
    "ê¶Œì¥ì‚¬í•­ ìƒì„±": "Generate recommendations",
}

def translate_korean_text(text):
    """Translate Korean text to English using the mappings."""
    for korean, english in TRANSLATIONS.items():
        text = text.replace(korean, english)
    return text

def process_file(file_path):
    """Process a single Python file to translate Korean comments and docstrings."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        original_content = content
        
        # Process docstrings (""" or ''')
        def replace_docstring(match):
            docstring = match.group(0)
            translated = translate_korean_text(docstring)
            return translated
        
        # Match docstrings
        content = re.sub(r'"""[^"]*"""', replace_docstring, content, flags=re.DOTALL)
        content = re.sub(r"'''[^']*'''", replace_docstring, content, flags=re.DOTALL)
        
        # Process single-line comments
        def replace_comment(match):
            comment = match.group(0)
            translated = translate_korean_text(comment)
            return translated
        
        # Match comments starting with # followed by Korean characters
        content = re.sub(r'#[^\n]*[ê°€-í£][^\n]*', replace_comment, content)
        
        # Write back if changed
        if content != original_content:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… Updated: {file_path}")
            return True
        else:
            print(f"â­ï¸  No changes: {file_path}")
            return False
            
    except Exception as e:
        print(f"âŒ Error processing {file_path}: {e}")
        return False

def main():
    """Main function to process all Python files."""
    print("ğŸ”„ Converting Korean comments and docstrings to English...")
    print("=" * 60)
    
    # Get project root directory
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    # Directories to process
    directories = [
        project_root / "examples",
        project_root / "ranx_k",
        project_root / "scripts"
    ]
    
    total_files = 0
    updated_files = 0
    
    for directory in directories:
        if directory.exists():
            print(f"\nğŸ“ Processing directory: {directory}")
            for py_file in directory.rglob("*.py"):
                if py_file.name == "fix_korean_comments.py":
                    continue  # Skip this script itself
                total_files += 1
                if process_file(py_file):
                    updated_files += 1
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š Summary:")
    print(f"   Total files processed: {total_files}")
    print(f"   Files updated: {updated_files}")
    print(f"   Files unchanged: {total_files - updated_files}")
    print("âœ… Korean to English conversion completed!")

if __name__ == "__main__":
    main()