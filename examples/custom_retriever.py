#!/usr/bin/env python3
"""
ranx-k Custom Retriever Implementation Example

This example demonstrates how to implement custom retrievers compatible with ranx-k.
"""

import numpy as np
from typing import List, Any
from ranx_k.tokenizers import KiwiTokenizer
from ranx_k.evaluation import simple_kiwi_rouge_evaluation

class Document:
    """Document class"""
    def __init__(self, content: str, metadata: dict = None):
        self.page_content = content
        self.metadata = metadata or {}

class SimpleVectorRetriever:
    """Simple vector-based retriever"""
    
    def __init__(self, documents: List[str]):
        self.documents = [Document(doc) for doc in documents]
        self.tokenizer = KiwiTokenizer(method='morphs', use_stopwords=True)
        self.vocab = self._build_vocabulary()
        self.doc_vectors = self._vectorize_documents()
    
    def _build_vocabulary(self):
        """Build vocabulary from all documents"""
        vocab = set()
        for doc in self.documents:
            tokens = self.tokenizer.tokenize(doc.page_content)
            vocab.update(tokens)
        return {word: i for i, word in enumerate(sorted(vocab))}
    
    def _vectorize_documents(self):
        """Convert documents to vectors"""
        vectors = []
        for doc in self.documents:
            vector = self._text_to_vector(doc.page_content)
            vectors.append(vector)
        return np.array(vectors)
    
    def _text_to_vector(self, text: str):
        """Convert text to TF vector"""
        tokens = self.tokenizer.tokenize(text)
        vector = np.zeros(len(self.vocab))
        
        for token in tokens:
            if token in self.vocab:
                vector[self.vocab[token]] += 1
        
        # L2 normalization
        norm = np.linalg.norm(vector)
        if norm > 0:
            vector = vector / norm
        
        return vector
    
    def invoke(self, query: str, top_k: int = 10) -> List[Document]:
        """Search for relevant documents for query"""
        query_vector = self._text_to_vector(query)
        
        # Calculate cosine similarity
        similarities = np.dot(self.doc_vectors, query_vector)
        
        # Select top k documents
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        return [self.documents[i] for i in top_indices if similarities[i] > 0]

class KeywordRetriever:
    """Keyword-based retriever"""
    
    def __init__(self, documents: List[str]):
        self.documents = [Document(doc) for doc in documents]
        self.tokenizer = KiwiTokenizer(method='morphs', use_stopwords=True)
    
    def invoke(self, query: str, top_k: int = 10) -> List[Document]:
        """Keyword matching based search"""
        query_tokens = set(self.tokenizer.tokenize(query))
        
        scored_docs = []
        for doc in self.documents:
            doc_tokens = set(self.tokenizer.tokenize(doc.page_content))
            
            # Calculate intersection-based score
            overlap = len(query_tokens & doc_tokens)
            if overlap > 0:
                # Jaccard similarity
                union = len(query_tokens | doc_tokens)
                score = overlap / union
                scored_docs.append((score, doc))
        
        # Sort by score
        scored_docs.sort(key=lambda x: x[0], reverse=True)
        
        return [doc for score, doc in scored_docs[:top_k]]

class HybridRetriever:
    """Vector + Keyword Hybrid retriever"""
    
    def __init__(self, documents: List[str], vector_weight: float = 0.7):
        self.vector_retriever = SimpleVectorRetriever(documents)
        self.keyword_retriever = KeywordRetriever(documents)
        self.vector_weight = vector_weight
        self.keyword_weight = 1.0 - vector_weight
    
    def invoke(self, query: str, top_k: int = 10) -> List[Document]:
        """Perform hybrid search"""
        # Get results from each retriever
        vector_results = self.vector_retriever.invoke(query, top_k * 2)
        keyword_results = self.keyword_retriever.invoke(query, top_k * 2)
        
        # Aggregate scores by document
        doc_scores = {}
        
        # Vector search scores
        for i, doc in enumerate(vector_results):
            score = (len(vector_results) - i) / len(vector_results)  # Rank-based score
            doc_scores[doc.page_content] = doc_scores.get(doc.page_content, 0) + \
                                         score * self.vector_weight
        
        # Keyword search scores
        for i, doc in enumerate(keyword_results):
            score = (len(keyword_results) - i) / len(keyword_results)
            doc_scores[doc.page_content] = doc_scores.get(doc.page_content, 0) + \
                                         score * self.keyword_weight
        
        # Sort by score
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)
        
        # Return Document objects
        result_docs = []
        doc_map = {doc.page_content: doc for doc in 
                  self.vector_retriever.documents}
        
        for content, score in sorted_docs[:top_k]:
            if content in doc_map:
                result_docs.append(doc_map[content])
        
        return result_docs

def main():
    print("ğŸ” ranx-k Custom Retriever Example | ranx-k ì»¤ìŠ¤í…€ ê²€ìƒ‰ê¸° ì˜ˆì œ")
    print("=" * 50)
    
    # Sample document collection
    documents = [
        "ìì—°ì–´ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì…ë‹ˆë‹¤.",
        "RAG ì‹œìŠ¤í…œì€ ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ë¡œ ì •ë³´ ê²€ìƒ‰ê³¼ í…ìŠ¤íŠ¸ ìƒì„±ì„ ê²°í•©í•©ë‹ˆë‹¤.",
        "í•œêµ­ì–´ í† í°í™”ëŠ” êµì°©ì–´ì  íŠ¹ì„± ë•Œë¬¸ì— í˜•íƒœì†Œ ë¶„ì„ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
        "ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì€ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ë¡œ í‰ê°€ë©ë‹ˆë‹¤.",
        "KiwiëŠ” í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ì— íŠ¹í™”ëœ ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.",
        "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ì—ëŠ” ëŒ€ëŸ‰ì˜ ë¼ë²¨ë§ëœ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
        "ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì–¸ì–´ ëª¨ë¸ì€ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "ê²€ìƒ‰ ì—”ì§„ ìµœì í™”ëŠ” ì›¹ì‚¬ì´íŠ¸ ê°€ì‹œì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.",
        "í…ìŠ¤íŠ¸ ë§ˆì´ë‹ì€ ë¹„êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ì—ì„œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.",
        "ì¶”ì²œ ì‹œìŠ¤í…œì€ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ í•™ìŠµí•˜ì—¬ ê°œì¸í™”ëœ ì½˜í…ì¸ ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
        "ì»´í“¨í„° ë¹„ì „ ê¸°ìˆ ì€ ì´ë¯¸ì§€ì™€ ì˜ìƒì„ ë¶„ì„í•˜ê³  ì´í•´í•©ë‹ˆë‹¤.",
        "ë°ì´í„° ì „ì²˜ë¦¬ëŠ” ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ì—ì„œ ì¤‘ìš”í•œ ë‹¨ê³„ì…ë‹ˆë‹¤."
    ]
    
    print(f"ğŸ“š Document Collection | ë¬¸ì„œ ì»¬ë ‰ì…˜: {len(documents)}ê°œ ë¬¸ì„œ")
    
    # Initialize various retrievers
    vector_retriever = SimpleVectorRetriever(documents)
    keyword_retriever = KeywordRetriever(documents)
    hybrid_retriever = HybridRetriever(documents, vector_weight=0.6)
    
    # Test queries
    test_queries = [
        "ìì—°ì–´ì²˜ë¦¬ ê¸°ìˆ ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "RAG ì‹œìŠ¤í…œì˜ íŠ¹ì§•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
        "í•œêµ­ì–´ í† í°í™” ë°©ë²•ì€?",
        "ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ê³¼ì •ì€?"
    ]
    
    print(f"ğŸ” Test Queries | í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {len(test_queries)}ê°œ")
    
    # 1. Compare results by retriever type
    print("\n1ï¸âƒ£ Results Comparison by Retriever Type | ê²€ìƒ‰ê¸°ë³„ ê²°ê³¼ ë¹„êµ")
    print("-" * 50)
    
    for i, query in enumerate(test_queries[:2]):  # First 2 queries only
        print(f"\nQuery | ì¿¼ë¦¬ {i+1}: {query}")
        print("=" * 40)
        
        # Vector search
        vector_results = vector_retriever.invoke(query, 3)
        print(f"\nğŸ”¢ Vector Search | ë²¡í„° ê²€ìƒ‰ ({len(vector_results)}ê°œ):")
        for j, doc in enumerate(vector_results, 1):
            print(f"  {j}. {doc.page_content[:50]}...")
        
        # Keyword search
        keyword_results = keyword_retriever.invoke(query, 3)
        print(f"\nğŸ”¤ Keyword Search | í‚¤ì›Œë“œ ê²€ìƒ‰ ({len(keyword_results)}ê°œ):")
        for j, doc in enumerate(keyword_results, 1):
            print(f"  {j}. {doc.page_content[:50]}...")
        
        # Hybrid search
        hybrid_results = hybrid_retriever.invoke(query, 3)
        print(f"\nğŸ”€ Hybrid Search | í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ({len(hybrid_results)}ê°œ):")
        for j, doc in enumerate(hybrid_results, 1):
            print(f"  {j}. {doc.page_content[:50]}...")
    
    # 2. Performance evaluation
    print("\n2ï¸âƒ£ Retriever Performance Evaluation | ê²€ìƒ‰ê¸° ì„±ëŠ¥ í‰ê°€")
    print("-" * 30)
    
    # Prepare evaluation data
    eval_questions = [
        "ìì—°ì–´ì²˜ë¦¬ ê¸°ìˆ ì´ë€?",
        "RAG ì‹œìŠ¤í…œ ì„¤ëª…",
        "í•œêµ­ì–´ í† í°í™” íŠ¹ì§•",
        "ì •ë³´ ê²€ìƒ‰ í‰ê°€ ë°©ë²•"
    ]
    
    eval_references = [
        ["ìì—°ì–´ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì…ë‹ˆë‹¤."],
        ["RAG ì‹œìŠ¤í…œì€ ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ë¡œ ì •ë³´ ê²€ìƒ‰ê³¼ í…ìŠ¤íŠ¸ ìƒì„±ì„ ê²°í•©í•©ë‹ˆë‹¤."],
        ["í•œêµ­ì–´ í† í°í™”ëŠ” êµì°©ì–´ì  íŠ¹ì„± ë•Œë¬¸ì— í˜•íƒœì†Œ ë¶„ì„ì´ ì¤‘ìš”í•©ë‹ˆë‹¤."],
        ["ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì€ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ë¡œ í‰ê°€ë©ë‹ˆë‹¤."]
    ]
    
    retrievers = [
        ("Vector Retriever | ë²¡í„° ê²€ìƒ‰ê¸°", vector_retriever),
        ("Keyword Retriever | í‚¤ì›Œë“œ ê²€ìƒ‰ê¸°", keyword_retriever),  
        ("Hybrid Retriever | í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°", hybrid_retriever)
    ]
    
    print(f"{'ê²€ìƒ‰ê¸°':<15} {'ROUGE-1':<10} {'ROUGE-2':<10} {'ROUGE-L':<10}")
    print("-" * 50)
    
    for name, retriever in retrievers:
        try:
            results = simple_kiwi_rouge_evaluation(
                retriever=retriever,
                questions=eval_questions,
                reference_contexts=eval_references,
                k=3
            )
            
            rouge1 = results.get('kiwi_rouge1@3', 0.0)
            rouge2 = results.get('kiwi_rouge2@3', 0.0)
            rougeL = results.get('kiwi_rougeL@3', 0.0)
            
            print(f"{name:<15} {rouge1:<10.3f} {rouge2:<10.3f} {rougeL:<10.3f}")
            
        except Exception as e:
            print(f"{name:<15} Error | ì˜¤ë¥˜: {str(e)}")
    
    # 3. ì„±ëŠ¥ ë¶„ì„
    print("\n3ï¸âƒ£ Performance Characteristics Analysis | ì„±ëŠ¥ íŠ¹ì„± ë¶„ì„")
    print("-" * 25)
    
    analysis_query = "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì€?"
    
    print(f"Analysis Query | ë¶„ì„ ì¿¼ë¦¬: {analysis_query}")
    print("\nRetriever Characteristics | ê° ê²€ìƒ‰ê¸°ì˜ íŠ¹ì„±:")
    
    # Vector retriever analysis
    vector_results = vector_retriever.invoke(analysis_query, 5)
    print(f"\nğŸ”¢ Vector Retriever | ë²¡í„° ê²€ìƒ‰ê¸°:")
    print(f"  - Semantic similarity-based | ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜")
    print(f"  - Search results | ê²€ìƒ‰ ê²°ê³¼: {len(vector_results)}ê°œ")
    print(f"  - Advantages: Synonyms and similar concept search | ì¥ì : ë™ì˜ì–´, ìœ ì‚¬ ê°œë… ê²€ìƒ‰ ê°€ëŠ¥")
    
    # Keyword retriever analysis
    keyword_results = keyword_retriever.invoke(analysis_query, 5)
    print(f"\nğŸ”¤ Keyword Retriever | í‚¤ì›Œë“œ ê²€ìƒ‰ê¸°:")
    print(f"  - Exact keyword matching | ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­")
    print(f"  - Search results | ê²€ìƒ‰ ê²°ê³¼: {len(keyword_results)}ê°œ")
    print(f"  - Advantages: Fast speed, exact matching | ì¥ì : ë¹ ë¥¸ ì†ë„, ì •í™•í•œ ë§¤ì¹­")
    
    # Hybrid retriever analysis
    hybrid_results = hybrid_retriever.invoke(analysis_query, 5)
    print(f"\nğŸ”€ Hybrid Retriever | í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°:")
    print(f"  - Vector + Keyword combination | ë²¡í„° + í‚¤ì›Œë“œ ê²°í•©")
    print(f"  - Search results | ê²€ìƒ‰ ê²°ê³¼: {len(hybrid_results)}ê°œ")
    print(f"  - Advantages: Combines benefits of both approaches | ì¥ì : ë‘ ë°©ì‹ì˜ ì¥ì  ê²°í•©")
    
    print("\nâœ… Custom Retriever Example Completed | ì»¤ìŠ¤í…€ ê²€ìƒ‰ê¸° ì˜ˆì œ ì™„ë£Œ!")
    print("\nğŸ’¡ Implementation Guide | êµ¬í˜„ ê°€ì´ë“œ:")
    print("1. Just implement invoke(query) method for ranx-k compatibility | invoke(query) ë©”ì„œë“œë§Œ êµ¬í˜„í•˜ë©´ ranx-kì™€ í˜¸í™˜")
    print("2. Document object needs page_content attribute | Document ê°ì²´ì˜ page_content ì†ì„± í•„ìš”")
    print("3. Various search algorithm combinations possible | ë‹¤ì–‘í•œ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ì¡°í•© ê°€ëŠ¥")

if __name__ == "__main__":
    main()